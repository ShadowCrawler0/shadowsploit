import requests
from bs4 import BeautifulSoup

def web_spider(url):
    try:
        # Send a GET request to the specified URL
        response = requests.get(url)
        
        # Check if the request was successful (status code 200)
        if response.status_code == 200:
            # Parse the HTML content using BeautifulSoup
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Extract links
            links = [link.get('href') for link in soup.find_all('a')]
            
            # Extract images
            images = [image.get('src') for image in soup.find_all('img')]
            
            # Extract other relevant information (e.g., scripts, stylesheets)
            scripts = [script.get('src') for script in soup.find_all('script')]
            stylesheets = [stylesheet.get('href') for stylesheet in soup.find_all('link', rel='stylesheet')]
            
            # Return the extracted information
            return {
                'links': links,
                'images': images,
                'scripts': scripts,
                'stylesheets': stylesheets
            }
        else:
            print(f"Failed to retrieve content from {url}. Status code: {response.status_code}")
            return None
    except requests.exceptions.RequestException as e:
        print(f"Error occurred while requesting {url}: {e}")
        return None

# Example usage
url = input("Enter target URL: ")
extracted_info = web_spider(url)

if extracted_info:
    print("Extracted information:")
    print("Links:")
    print(extracted_info['links'])
    print("Images:")
    print(extracted_info['images'])
    print("Scripts:")
    print(extracted_info['scripts'])
    print("Stylesheets:")
    print(extracted_info['stylesheets'])
else:
    print("No extracted information available.")
